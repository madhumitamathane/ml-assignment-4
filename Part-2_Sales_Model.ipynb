{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = \"./data/Sales_Transactions_Dataset_Weekly.csv\"\n",
    "DROP_COLUMNS = [\n",
    "    \"Product_Code\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# metric functions\n",
    "# --------------------------------------------\n",
    "def total_sum_of_squares_df(df, centroid = None):\n",
    "    \"\"\" Calculates and returns the TTS of the given DataFrame \"\"\"\n",
    "    if centroid is None:\n",
    "        centroid = find_centroid_df(df)\n",
    "        \n",
    "    return total_sum_of_squares(df.as_matrix(), centroid)\n",
    "\n",
    "def total_sum_of_squares(data, centroid):\n",
    "    \"\"\" Calculates and returns the TTS of the given matrix\n",
    "    \n",
    "    Arguments:\n",
    "      data - Iterable<Iterable>\n",
    "      centroid - Array\n",
    "    \"\"\"        \n",
    "    total = 0\n",
    "    \n",
    "    for row in data:\n",
    "        for index, value in enumerate(row):\n",
    "            diff = value - centroid[index]\n",
    "            diffsq = diff ** 2\n",
    "            total += diffsq\n",
    "            \n",
    "    return total\n",
    "\n",
    "\n",
    "def find_centroid_df(df):\n",
    "    \"\"\" Calculates and returns the centroid for a DataFrame \"\"\"\n",
    "    return df.mean()\n",
    "\n",
    "# clustering functions\n",
    "# --------------------------\n",
    "\n",
    "def get_cluster_indexes(cluster_assignments):\n",
    "    cluster_slices = {}\n",
    "    \n",
    "    for index, assignment in enumerate(assignments):\n",
    "        if assignment not in cluster_slices:\n",
    "            cluster_slices[assignment] = list()\n",
    "            \n",
    "        cluster_slices[assignment].append(index)\n",
    "        \n",
    "    return cluster_slices\n",
    "\n",
    "def get_cluster_data(df, assignments):\n",
    "    cluster_indexes = get_cluster_indexes(assignments)\n",
    "    \n",
    "    cluster_data = {k: df.iloc[v] for k, v in cluster_indexes.items()}\n",
    "    \n",
    "    return cluster_data\n",
    "\n",
    "def get_clusters(df, assignments):\n",
    "    \"\"\"Returns an array of tuples with (<cluster>, <cluster_centroid>, <cluster_data_points>)\"\"\"\n",
    "    \n",
    "    return [\n",
    "        (cluster, find_centroid_df(cluster_data), cluster_data) \n",
    "        for cluster, cluster_data \n",
    "        in get_cluster_data(df, assignments).items()\n",
    "    ]\n",
    "    \n",
    "\n",
    "# model runners\n",
    "# ------------------------------------------\n",
    "\n",
    "def run_kmeans(model, data):\n",
    "    model.fit(data)\n",
    "    return model.predict(data)\n",
    "\n",
    "# data functions \n",
    "# -------------------------------------------\n",
    "\n",
    "def clean_data(data):\n",
    "    # Strip whitespaces from all string values\n",
    "    # and drop all na rows\n",
    "    data = data.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x) \\\n",
    "               .dropna()\n",
    "            \n",
    "    return data\n",
    "\n",
    "def read_data(path):\n",
    "    dataset = pd.read_csv(path, header=0)\n",
    "    \n",
    "    dataset = dataset.iloc[:,55:]\n",
    "    \n",
    "    dataset = clean_data(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = read_data(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = total_sum_of_squares_df(df)\n",
    "print(\"tss for data = %s\" % tss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"KMeans\", lambda k: KMeans(n_clusters=k), run_kmeans)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, create_model, run_model in models:\n",
    "    print(\"-------------------------------\")\n",
    "    print(model_name)\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"\")\n",
    "    for k in range(2,10):\n",
    "        print(\"Calculating %s clusters...\" % k)\n",
    "        print(\"\")\n",
    "        model = create_model(k)\n",
    "        assignments = run_model(model, df)\n",
    "        clusters = get_clusters(df, assignments)\n",
    "\n",
    "        twss = 0\n",
    "        for cluster, centroid, cluster_slice in clusters:\n",
    "            cluster_tss = total_sum_of_squares_df(cluster_slice, centroid)\n",
    "            print(\"cluster %s | tss = %s | size = %s\" % (cluster, cluster_tss, len(cluster_slice)))\n",
    "            twss += cluster_tss\n",
    "\n",
    "        print(\"twss/tss = %s/%s = %s\" % (twss, tss, twss / tss))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
