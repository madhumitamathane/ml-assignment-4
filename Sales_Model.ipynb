{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = \"./data/Sales_Transactions_Dataset_Weekly.csv\"\n",
    "DUMMY_COLUMNS = [\n",
    "    \"Product_Code\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# metric functions\n",
    "# --------------------------------------------\n",
    "def total_sum_of_squares_df(df, centroid = None):\n",
    "    \"\"\" Calculates and returns the TTS of the given DataFrame \"\"\"\n",
    "    if centroid is None:\n",
    "        centroid = find_centroid_df(df)\n",
    "        \n",
    "    return total_sum_of_squares(df.as_matrix(), centroid)\n",
    "\n",
    "def total_sum_of_squares(data, centroid):\n",
    "    \"\"\" Calculates and returns the TTS of the given matrix\n",
    "    \n",
    "    Arguments:\n",
    "      data - Iterable<Iterable>\n",
    "      centroid - Array\n",
    "    \"\"\"        \n",
    "    total = 0\n",
    "    \n",
    "    for row in data:\n",
    "        for index, value in enumerate(row):\n",
    "            diff = value - centroid[index]\n",
    "            diffsq = diff ** 2\n",
    "            total += diffsq\n",
    "            \n",
    "    return total\n",
    "\n",
    "\n",
    "def find_centroid_df(df):\n",
    "    \"\"\" Calculates and returns the centroid for a DataFrame \"\"\"\n",
    "    return df.mean()\n",
    "\n",
    "# clustering functions\n",
    "# --------------------------\n",
    "\n",
    "def get_cluster_indexes(cluster_assignments):\n",
    "    cluster_slices = {}\n",
    "    \n",
    "    for index, assignment in enumerate(assignments):\n",
    "        if assignment not in cluster_slices:\n",
    "            cluster_slices[assignment] = list()\n",
    "            \n",
    "        cluster_slices[assignment].append(index)\n",
    "        \n",
    "    return cluster_slices\n",
    "\n",
    "def get_cluster_data(df, assignments):\n",
    "    cluster_indexes = get_cluster_indexes(assignments)\n",
    "    \n",
    "    cluster_data = {k: df.iloc[v] for k, v in cluster_indexes.items()}\n",
    "    \n",
    "    return cluster_data\n",
    "\n",
    "def get_clusters(df, assignments):\n",
    "    \"\"\"Returns an array of tuples with (<cluster>, <cluster_centroid>, <cluster_data_points>)\"\"\"\n",
    "    \n",
    "    return [\n",
    "        (cluster, find_centroid_df(cluster_data), cluster_data) \n",
    "        for cluster, cluster_data \n",
    "        in get_cluster_data(df, assignments).items()\n",
    "    ]\n",
    "    \n",
    "\n",
    "# model runners\n",
    "# ------------------------------------------\n",
    "\n",
    "#def run_gaussian_mixture(model, data):\n",
    "    model.fit(data)\n",
    "    return model.predict(data)\n",
    "\n",
    "def run_kmeans(model, data):\n",
    "    model.fit(data)\n",
    "    return model.predict(data)\n",
    "\n",
    "#def run_hclustering(model, data):\n",
    "    return model.fit_predict(data)\n",
    "\n",
    "# data functions \n",
    "# -------------------------------------------\n",
    "\n",
    "def clean_data(data):\n",
    "    # Strip whitespaces from all string values\n",
    "    # and replace \"?\" with None,\n",
    "    # and drop all na rows\n",
    "    data = data.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x) \\\n",
    "               .replace([\"?\"], [None]) \\\n",
    "               .dropna()\n",
    "\n",
    "    return data\n",
    "\n",
    "def prepare_data(data):\n",
    "    return pd.get_dummies(data, columns=DUMMY_COLUMNS)\n",
    "\n",
    "def read_data(path):\n",
    "    dataset = pd.read_csv(path, header=0)\n",
    "    dataset = clean_data(dataset)\n",
    "    dataset = prepare_data(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = read_data(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tss for data = 6314001.08426\n"
     ]
    }
   ],
   "source": [
    "tss = total_sum_of_squares_df(df)\n",
    "print(\"tss for data = %s\" % tss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"KMeans\", lambda k: KMeans(n_clusters=k), run_kmeans)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "KMeans\n",
      "-------------------------------\n",
      "\n",
      "Calculating 2 clusters...\n",
      "\n",
      "cluster 0 | tss = 905973.114504 | size = 667\n",
      "cluster 1 | tss = 545136.779334 | size = 144\n",
      "twss/tss = 1451109.89384/6314001.08426 = 0.22982414391\n",
      "\n",
      "Calculating 3 clusters...\n",
      "\n",
      "cluster 2 | tss = 267592.717997 | size = 197\n",
      "cluster 0 | tss = 134070.912504 | size = 490\n",
      "cluster 1 | tss = 308460.928885 | size = 124\n",
      "twss/tss = 710124.559386/6314001.08426 = 0.112468235262\n",
      "\n",
      "Calculating 4 clusters...\n",
      "\n",
      "cluster 3 | tss = 119579.584783 | size = 164\n",
      "cluster 0 | tss = 122884.926345 | size = 482\n",
      "cluster 2 | tss = 66633.9667111 | size = 45\n",
      "cluster 1 | tss = 282654.440475 | size = 120\n",
      "twss/tss = 591752.918314/6314001.08426 = 0.0937207501896\n",
      "\n",
      "Calculating 5 clusters...\n",
      "\n",
      "cluster 2 | tss = 110425.82482 | size = 156\n",
      "cluster 0 | tss = 50329.3856612 | size = 188\n",
      "cluster 3 | tss = 66633.9667111 | size = 45\n",
      "cluster 1 | tss = 282654.440475 | size = 120\n",
      "cluster 4 | tss = 11730.1060262 | size = 302\n",
      "twss/tss = 521773.723693/6314001.08426 = 0.0826375727103\n",
      "\n",
      "Calculating 6 clusters...\n",
      "\n",
      "cluster 0 | tss = 110425.82482 | size = 156\n",
      "cluster 2 | tss = 50329.3856612 | size = 188\n",
      "cluster 5 | tss = 61680.8338682 | size = 44\n",
      "cluster 1 | tss = 120420.237592 | size = 49\n",
      "cluster 4 | tss = 147625.218644 | size = 72\n",
      "cluster 3 | tss = 11730.1060262 | size = 302\n",
      "twss/tss = 502211.606612/6314001.08426 = 0.0795393602108\n",
      "\n",
      "Calculating 7 clusters...\n",
      "\n",
      "cluster 3 | tss = 62268.0290811 | size = 111\n",
      "cluster 5 | tss = 50329.3856612 | size = 188\n",
      "cluster 4 | tss = 61680.8338682 | size = 44\n",
      "cluster 2 | tss = 31818.9051289 | size = 45\n",
      "cluster 6 | tss = 127040.975654 | size = 52\n",
      "cluster 1 | tss = 140957.678849 | size = 69\n",
      "cluster 0 | tss = 11730.1060262 | size = 302\n",
      "twss/tss = 485825.914269/6314001.08426 = 0.07694422408\n",
      "\n",
      "Calculating 8 clusters...\n",
      "\n",
      "cluster 3 | tss = 64782.7369079 | size = 114\n",
      "cluster 4 | tss = 50329.3856612 | size = 188\n",
      "cluster 5 | tss = 46647.49547 | size = 40\n",
      "cluster 7 | tss = 29292.2038238 | size = 42\n",
      "cluster 0 | tss = 115610.886298 | size = 47\n",
      "cluster 6 | tss = 148155.097071 | size = 73\n",
      "cluster 1 | tss = 11730.1060262 | size = 302\n",
      "cluster 2 | tss = 7121.86352 | size = 5\n",
      "twss/tss = 473669.774778/6314001.08426 = 0.0750189568322\n",
      "\n",
      "Calculating 9 clusters...\n",
      "\n",
      "cluster 5 | tss = 63757.0142053 | size = 113\n",
      "cluster 0 | tss = 50329.3856612 | size = 188\n",
      "cluster 3 | tss = 46647.49547 | size = 40\n",
      "cluster 2 | tss = 30307.3640047 | size = 43\n",
      "cluster 1 | tss = 106548.147553 | size = 47\n",
      "cluster 6 | tss = 137403.764446 | size = 70\n",
      "cluster 7 | tss = 8880.40393333 | size = 3\n",
      "cluster 4 | tss = 11730.1060262 | size = 302\n",
      "cluster 8 | tss = 7121.86352 | size = 5\n",
      "twss/tss = 462725.54482/6314001.08426 = 0.0732856296103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name, create_model, run_model in models:\n",
    "    print(\"-------------------------------\")\n",
    "    print(model_name)\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"\")\n",
    "    for k in range(2,10):\n",
    "        print(\"Calculating %s clusters...\" % k)\n",
    "        print(\"\")\n",
    "        model = create_model(k)\n",
    "        assignments = run_model(model, df)\n",
    "        clusters = get_clusters(df, assignments)\n",
    "\n",
    "        twss = 0\n",
    "        for cluster, centroid, cluster_slice in clusters:\n",
    "            cluster_tss = total_sum_of_squares_df(cluster_slice, centroid)\n",
    "            print(\"cluster %s | tss = %s | size = %s\" % (cluster, cluster_tss, len(cluster_slice)))\n",
    "            twss += cluster_tss\n",
    "\n",
    "        print(\"twss/tss = %s/%s = %s\" % (twss, tss, twss / tss))\n",
    "        print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
